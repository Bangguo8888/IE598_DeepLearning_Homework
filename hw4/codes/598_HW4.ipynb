{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Homework 4\n",
    "## Bangguo Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Routine for decoding the CIFAR-10 binary file format.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Process images of this size. Note that this differs from the original CIFAR\n",
    "# image size of 32 x 32. If one alters this number, then the entire model\n",
    "# architecture will change and any model would need to be retrained.\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "\n",
    "def read_cifar10(filename_queue):\n",
    "    \"\"\"Reads and parses examples from CIFAR10 data files.\n",
    "\n",
    "    Recommendation: if you want N-way read parallelism, call this function\n",
    "    N times.  This will give you N independent Readers reading different\n",
    "    files & positions within those files, which will give better mixing of\n",
    "    examples.\n",
    "\n",
    "    Args:\n",
    "        filename_queue: A queue of strings with the filenames to read from.\n",
    "\n",
    "    Returns:\n",
    "        An object representing a single example, with the following fields:\n",
    "            height: number of rows in the result (32)\n",
    "            width: number of columns in the result (32)\n",
    "            depth: number of color channels in the result (3)\n",
    "            key: a scalar string Tensor describing the filename & record number\n",
    "                for this example.\n",
    "            label: an int32 Tensor with the label in the range 0..9.\n",
    "            uint8image: a [height, width, depth] uint8 Tensor with the image data\n",
    "    \"\"\"\n",
    "\n",
    "    class CIFAR10Record(object):\n",
    "        pass\n",
    "    result = CIFAR10Record()\n",
    "\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    label_bytes = 1  # 2 for CIFAR-100\n",
    "    result.height = 32\n",
    "    result.width = 32\n",
    "    result.depth = 3\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    # Every record consists of a label followed by the image, with a\n",
    "    # fixed number of bytes for each.\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "\n",
    "    # Read a record, getting filenames from the filename_queue.  No\n",
    "    # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "    # and footer_bytes at their default of 0.\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "\n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "    # The first bytes represent the label, which we convert from uint8->int32.\n",
    "    result.label = tf.cast(\n",
    "            tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "    # The remaining bytes after the label represent the image, which we reshape\n",
    "    # from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = tf.reshape(\n",
    "            tf.strided_slice(record_bytes, [label_bytes],\n",
    "                                             [label_bytes + image_bytes]),\n",
    "            [result.depth, result.height, result.width])\n",
    "    # Convert from [depth, height, width] to [height, width, depth].\n",
    "    result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples,\n",
    "                                    batch_size, shuffle):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "\n",
    "    Args:\n",
    "        image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "        label: 1-D Tensor of type.int32\n",
    "        min_queue_examples: int32, minimum number of samples to retain\n",
    "            in the queue that provides of batches of examples.\n",
    "        batch_size: Number of images per batch.\n",
    "        shuffle: boolean indicating whether to use a shuffling queue.\n",
    "\n",
    "    Returns:\n",
    "        images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "        labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    # Create a queue that shuffles the examples, and then\n",
    "    # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 8\n",
    "    if shuffle:\n",
    "        images, label_batch = tf.train.shuffle_batch(\n",
    "                [image, label],\n",
    "                batch_size=batch_size,\n",
    "                num_threads=num_preprocess_threads,\n",
    "                capacity=min_queue_examples + 3 * batch_size,\n",
    "                min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch(\n",
    "                [image, label],\n",
    "                batch_size=batch_size,\n",
    "                num_threads=num_preprocess_threads,\n",
    "                capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images)\n",
    "\n",
    "    return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "def get_inputs(data_dir, batch_size, is_test=False):\n",
    "    \"\"\"Construct distorted input for CIFAR training using the Reader ops.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to the CIFAR-10 data directory.\n",
    "        batch_size: Number of images per batch.\n",
    "\n",
    "    Returns:\n",
    "        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "        labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    if not is_test:\n",
    "        filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "                                 for i in xrange(1, 6)]\n",
    "        num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN\n",
    "    else:\n",
    "        filenames = [os.path.join(data_dir, 'test_batch.bin')]\n",
    "        num_examples_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL\n",
    "\n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError('Failed to find file: ' + f)\n",
    "\n",
    "    # Create a queue that produces the filenames to read.\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "    # Read examples from files in the filename queue.\n",
    "    read_input = read_cifar10(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "    height = IMAGE_SIZE\n",
    "    width = IMAGE_SIZE\n",
    "\n",
    "    # Image processing for training the network. Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # the order their operation.\n",
    "    # NOTE: since per_image_standardization zeros the mean and makes\n",
    "    # the stddev unit, this likely has no effect see tensorflow#1458.\n",
    "    if not is_test:\n",
    "        # Randomly flip the image horizontally.\n",
    "        distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n",
    "        distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "        # distorted_image = tf.image.random_brightness(distorted_image,max_delta=63)\n",
    "        # distorted_image = tf.image.random_contrast(distorted_image,lower=0.2, upper=1.8)\n",
    "        #distorted_image = distorted_image + tf.random_normal(shape=tf.shape(distorted_image), mean=0.0, stddev=0.2, dtype=tf.float32) \n",
    "    else:\n",
    "        distorted_image = tf.image.resize_image_with_crop_or_pad(reshaped_image, height, width)\n",
    "\n",
    "    # DON'T WANT TO DO THIS SINCE THE OUTPUT FROM THE GENERATOR IS SIGMOID\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    # float_image = tf.image.per_image_standardization(distorted_image)\n",
    "    \n",
    "    #float_image = tf.multiply(distorted_image,1.0/255.0)\n",
    "    float_image = tf.multiply(distorted_image,1.0/128.0)\n",
    "    float_image = tf.add(float_image,-1.0)\n",
    "\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "\n",
    "    # Ensure that the random shuffling has good mixing properties.\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *\n",
    "                                                     min_fraction_of_examples_in_queue)\n",
    "    print ('Filling queue with %d CIFAR images before starting to train. '\n",
    "                 'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "    # Generate a batch of images and labels by building up a queue of examples.\n",
    "    return _generate_image_and_label_batch(float_image,read_input.label,min_queue_examples,batch_size,shuffle=True)\n",
    "\n",
    "def train_inputs(batch_size):\n",
    "    data_dir = 'cifar10_data/cifar-10-batches-bin/'\n",
    "    images, labels = get_inputs(data_dir=data_dir,batch_size=batch_size)\n",
    "    return images, labels\n",
    "\n",
    "def test_inputs(batch_size):\n",
    "    data_dir = 'cifar10_data/cifar-10-batches-bin/'\n",
    "    images, labels = get_inputs(data_dir=data_dir,batch_size=batch_size, is_test=True)\n",
    "    return images, labels\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(8, 8)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample)\n",
    "    return fig\n",
    "\n",
    "def plot_weights(samples):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(8, 8)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        #ax.set_aspect('equal')\n",
    "        plt.imshow(sample)\n",
    "    return fig\n",
    "\n",
    "def plot_classes(samples):\n",
    "    fig = plt.figure(figsize=(10, 100))\n",
    "    gs = gridspec.GridSpec(1, 10)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        #ax.set_aspect('equal')\n",
    "        plt.imshow(sample)\n",
    "    return fig\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "\n",
    "from model import discriminator,generator\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    images, labels = train_inputs(batch_size)\n",
    "    images_test, labels_test = test_inputs(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('placeholder'):\n",
    "    X = tf.placeholder(tf.float32, [None, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    y = tf.placeholder(name='label',dtype=tf.float32,shape=[None,10])\n",
    "    keep_prob = tf.placeholder(tf.float32 ,shape=())\n",
    "    is_train = tf.placeholder(tf.bool ,shape=())\n",
    "    \n",
    "with tf.variable_scope('GAN'):\n",
    "    D, D_logits, flat_features = discriminator(X, \n",
    "        keep_prob=keep_prob, is_train=is_train, reuse=False)\n",
    "\n",
    "with tf.variable_scope('D_loss'):\n",
    "    label = tf.concat([y,tf.zeros([batch_size,1])],axis=1)\n",
    "    d_loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=D_logits,labels=label))\n",
    "\n",
    "with tf.variable_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(D[:,:-1],1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "with tf.name_scope('gradients'):\n",
    "    grad_loss_over_X = tf.gradients(d_loss, X)[0]\n",
    "\n",
    "    grad_features_over_X = tf.gradients(\n",
    "        tf.reduce_mean(tf.diag_part(flat_features[0:64,0:64])),X)[0]\n",
    "    grad_logit_over_X = tf.gradients(\n",
    "        tf.reduce_mean(tf.diag_part(D_logits[0:10,0:10])),X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvar = tf.global_variables()\n",
    "saver = tf.train.Saver(dvar)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "saver.restore(sess,tf.train.latest_checkpoint('GAN/discriminator/'))\n",
    "#saver.restore(sess,tf.train.latest_checkpoint('discriminator_no_GAN/'))\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord)\n",
    "tf.train.start_queue_runners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch = np.load('X_batch_1.npy')\n",
    "labels_batch = np.load('labels_batch_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#X_batch, labels_batch = sess.run([images_test, labels_test])\n",
    "\n",
    "real_labels = labels_batch\n",
    "alternate_labels = labels_batch + 1\n",
    "alternate_labels[alternate_labels>=10]=0\n",
    "\n",
    "y_batch_real = np.zeros((batch_size,10))\n",
    "y_batch_real[np.arange(batch_size),real_labels] = 1\n",
    "\n",
    "y_batch_alternate = np.zeros((batch_size,10))\n",
    "y_batch_alternate[np.arange(batch_size),alternate_labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('X_batch_1', X_batch)\n",
    "np.save('labels_batch_1',labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.84375  ,  0.8515625,  0.890625 ],\n",
       "         [ 0.8125   ,  0.8203125,  0.859375 ],\n",
       "         [ 0.8125   ,  0.8203125,  0.859375 ],\n",
       "         ..., \n",
       "         [ 0.875    ,  0.8984375,  0.953125 ],\n",
       "         [ 0.875    ,  0.8984375,  0.953125 ],\n",
       "         [ 0.890625 ,  0.90625  ,  0.9453125]],\n",
       "\n",
       "        [[ 0.859375 ,  0.8671875,  0.90625  ],\n",
       "         [ 0.8203125,  0.828125 ,  0.8671875],\n",
       "         [ 0.8203125,  0.828125 ,  0.8671875],\n",
       "         ..., \n",
       "         [ 0.875    ,  0.8984375,  0.953125 ],\n",
       "         [ 0.8828125,  0.8984375,  0.953125 ],\n",
       "         [ 0.8984375,  0.90625  ,  0.9453125]],\n",
       "\n",
       "        [[ 0.875    ,  0.8828125,  0.921875 ],\n",
       "         [ 0.84375  ,  0.8515625,  0.890625 ],\n",
       "         [ 0.8359375,  0.84375  ,  0.8828125],\n",
       "         ..., \n",
       "         [ 0.8828125,  0.8984375,  0.9375   ],\n",
       "         [ 0.8984375,  0.90625  ,  0.953125 ],\n",
       "         [ 0.9140625,  0.921875 ,  0.9609375]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.875    ,  0.875    ,  0.890625 ],\n",
       "         [ 0.8515625,  0.8515625,  0.8671875],\n",
       "         [ 0.8515625,  0.8515625,  0.8671875],\n",
       "         ..., \n",
       "         [ 0.9453125,  0.9453125,  0.9453125],\n",
       "         [ 0.9609375,  0.9609375,  0.9609375],\n",
       "         [ 0.96875  ,  0.96875  ,  0.96875  ]],\n",
       "\n",
       "        [[ 0.875    ,  0.875    ,  0.890625 ],\n",
       "         [ 0.8515625,  0.8515625,  0.8671875],\n",
       "         [ 0.859375 ,  0.859375 ,  0.875    ],\n",
       "         ..., \n",
       "         [ 0.9453125,  0.9453125,  0.9453125],\n",
       "         [ 0.953125 ,  0.953125 ,  0.953125 ],\n",
       "         [ 0.9609375,  0.9609375,  0.9609375]],\n",
       "\n",
       "        [[ 0.8828125,  0.8828125,  0.8984375],\n",
       "         [ 0.859375 ,  0.859375 ,  0.8671875],\n",
       "         [ 0.859375 ,  0.859375 ,  0.8671875],\n",
       "         ..., \n",
       "         [ 0.9609375,  0.9609375,  0.9609375],\n",
       "         [ 0.96875  ,  0.96875  ,  0.96875  ],\n",
       "         [ 0.96875  ,  0.96875  ,  0.96875  ]]],\n",
       "\n",
       "\n",
       "       [[[-0.8828125, -0.875    , -0.859375 ],\n",
       "         [-0.859375 , -0.8515625, -0.8359375],\n",
       "         [-0.84375  , -0.8359375, -0.8203125],\n",
       "         ..., \n",
       "         [-0.6796875, -0.6875   , -0.640625 ],\n",
       "         [-0.6875   , -0.6953125, -0.6484375],\n",
       "         [-0.671875 , -0.6796875, -0.640625 ]],\n",
       "\n",
       "        [[-0.8671875, -0.859375 , -0.84375  ],\n",
       "         [-0.859375 , -0.8515625, -0.8359375],\n",
       "         [-0.828125 , -0.8203125, -0.8046875],\n",
       "         ..., \n",
       "         [-0.6484375, -0.6640625, -0.6015625],\n",
       "         [-0.6796875, -0.6875   , -0.625    ],\n",
       "         [-0.671875 , -0.6875   , -0.625    ]],\n",
       "\n",
       "        [[-0.8671875, -0.859375 , -0.84375  ],\n",
       "         [-0.875    , -0.8671875, -0.8515625],\n",
       "         [-0.859375 , -0.8515625, -0.8359375],\n",
       "         ..., \n",
       "         [-0.625    , -0.640625 , -0.5546875],\n",
       "         [-0.625    , -0.640625 , -0.5625   ],\n",
       "         [-0.6015625, -0.6171875, -0.53125  ]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.859375 ,  0.859375 ,  0.859375 ],\n",
       "         [ 0.859375 ,  0.859375 ,  0.859375 ],\n",
       "         [ 0.8984375,  0.8984375,  0.8984375],\n",
       "         ..., \n",
       "         [ 0.84375  ,  0.8203125,  0.8359375],\n",
       "         [ 0.8515625,  0.8359375,  0.84375  ],\n",
       "         [ 0.8203125,  0.8046875,  0.8125   ]],\n",
       "\n",
       "        [[ 0.875    ,  0.875    ,  0.875    ],\n",
       "         [ 0.875    ,  0.875    ,  0.875    ],\n",
       "         [ 0.890625 ,  0.890625 ,  0.890625 ],\n",
       "         ..., \n",
       "         [ 0.8515625,  0.8359375,  0.84375  ],\n",
       "         [ 0.84375  ,  0.828125 ,  0.8359375],\n",
       "         [ 0.8203125,  0.8046875,  0.8125   ]],\n",
       "\n",
       "        [[ 0.8828125,  0.8828125,  0.8828125],\n",
       "         [ 0.859375 ,  0.859375 ,  0.859375 ],\n",
       "         [ 0.875    ,  0.875    ,  0.875    ],\n",
       "         ..., \n",
       "         [ 0.84375  ,  0.828125 ,  0.8359375],\n",
       "         [ 0.8203125,  0.8046875,  0.8125   ],\n",
       "         [ 0.796875 ,  0.78125  ,  0.7890625]]],\n",
       "\n",
       "\n",
       "       [[[ 0.078125 ,  0.0859375,  0.0390625],\n",
       "         [ 0.078125 ,  0.0859375,  0.0390625],\n",
       "         [ 0.109375 ,  0.1171875,  0.0703125],\n",
       "         ..., \n",
       "         [-0.953125 , -0.90625  , -0.984375 ],\n",
       "         [-0.796875 , -0.7421875, -0.859375 ],\n",
       "         [-0.53125  , -0.4765625, -0.609375 ]],\n",
       "\n",
       "        [[-0.09375  , -0.0859375, -0.1328125],\n",
       "         [-0.140625 , -0.1328125, -0.1796875],\n",
       "         [ 0.0625   ,  0.0703125,  0.0234375],\n",
       "         ..., \n",
       "         [-0.984375 , -0.953125 , -1.       ],\n",
       "         [-0.8828125, -0.828125 , -0.9375   ],\n",
       "         [-0.65625  , -0.6015625, -0.734375 ]],\n",
       "\n",
       "        [[-0.0234375, -0.015625 , -0.0625   ],\n",
       "         [-0.2265625, -0.21875  , -0.265625 ],\n",
       "         [-0.03125  , -0.0234375, -0.0703125],\n",
       "         ..., \n",
       "         [-0.9609375, -0.921875 , -0.9921875],\n",
       "         [-0.8984375, -0.8515625, -0.9609375],\n",
       "         [-0.890625 , -0.8359375, -0.9609375]],\n",
       "\n",
       "        ..., \n",
       "        [[-0.125    , -0.1328125, -0.34375  ],\n",
       "         [-0.140625 , -0.140625 , -0.359375 ],\n",
       "         [-0.0390625, -0.0390625, -0.2578125],\n",
       "         ..., \n",
       "         [-0.015625 , -0.015625 , -0.265625 ],\n",
       "         [-0.3203125, -0.3125   , -0.5546875],\n",
       "         [-0.3515625, -0.3515625, -0.59375  ]],\n",
       "\n",
       "        [[-0.03125  , -0.0625   , -0.296875 ],\n",
       "         [-0.0390625, -0.046875 , -0.28125  ],\n",
       "         [ 0.015625 ,  0.03125  , -0.2109375],\n",
       "         ..., \n",
       "         [ 0.078125 ,  0.0625   , -0.1796875],\n",
       "         [-0.03125  , -0.046875 , -0.2890625],\n",
       "         [-0.15625  , -0.171875 , -0.4140625]],\n",
       "\n",
       "        [[-0.140625 , -0.1796875, -0.4140625],\n",
       "         [-0.109375 , -0.125    , -0.3671875],\n",
       "         [-0.0703125, -0.046875 , -0.3046875],\n",
       "         ..., \n",
       "         [-0.046875 , -0.0625   , -0.3046875],\n",
       "         [-0.015625 , -0.0390625, -0.28125  ],\n",
       "         [-0.1171875, -0.140625 , -0.3828125]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 0.1171875,  0.3046875,  0.5      ],\n",
       "         [-0.0078125,  0.125    ,  0.21875  ],\n",
       "         [ 0.0390625,  0.125    ,  0.296875 ],\n",
       "         ..., \n",
       "         [ 0.2109375,  0.484375 ,  0.828125 ],\n",
       "         [ 0.25     ,  0.53125  ,  0.875    ],\n",
       "         [-0.0390625,  0.1640625,  0.515625 ]],\n",
       "\n",
       "        [[-0.171875 ,  0.015625 ,  0.4375   ],\n",
       "         [-0.4765625, -0.3515625, -0.1328125],\n",
       "         [-0.3203125, -0.265625 , -0.0625   ],\n",
       "         ..., \n",
       "         [-0.1328125,  0.140625 ,  0.859375 ],\n",
       "         [-0.078125 ,  0.1953125,  0.8984375],\n",
       "         [-0.3125   , -0.109375 ,  0.4921875]],\n",
       "\n",
       "        [[-0.0078125,  0.21875  ,  0.7265625],\n",
       "         [-0.4140625, -0.2578125,  0.03125  ],\n",
       "         [-0.359375 , -0.2890625, -0.1484375],\n",
       "         ..., \n",
       "         [-0.109375 ,  0.1796875,  0.8828125],\n",
       "         [-0.0546875,  0.234375 ,  0.9453125],\n",
       "         [-0.2890625, -0.1015625,  0.5625   ]],\n",
       "\n",
       "        ..., \n",
       "        [[-0.046875 ,  0.25     ,  0.859375 ],\n",
       "         [-0.1328125,  0.15625  ,  0.8203125],\n",
       "         [-0.125    ,  0.171875 ,  0.84375  ],\n",
       "         ..., \n",
       "         [-0.125    ,  0.1640625,  0.8515625],\n",
       "         [-0.0703125,  0.21875  ,  0.90625  ],\n",
       "         [-0.2890625, -0.1171875,  0.5390625]],\n",
       "\n",
       "        [[-0.0703125,  0.234375 ,  0.84375  ],\n",
       "         [-0.15625  ,  0.1328125,  0.8046875],\n",
       "         [-0.1328125,  0.15625  ,  0.8359375],\n",
       "         ..., \n",
       "         [-0.1328125,  0.1484375,  0.8515625],\n",
       "         [-0.0703125,  0.203125 ,  0.90625  ],\n",
       "         [-0.2890625, -0.1328125,  0.5      ]],\n",
       "\n",
       "        [[-0.0625   ,  0.2109375,  0.84375  ],\n",
       "         [-0.15625  ,  0.109375 ,  0.796875 ],\n",
       "         [-0.1328125,  0.1328125,  0.828125 ],\n",
       "         ..., \n",
       "         [-0.1328125,  0.1328125,  0.8359375],\n",
       "         [-0.078125 ,  0.1875   ,  0.890625 ],\n",
       "         [-0.3046875, -0.1328125,  0.5078125]]],\n",
       "\n",
       "\n",
       "       [[[-0.5625   , -0.609375 , -0.6875   ],\n",
       "         [-0.7734375, -0.828125 , -0.859375 ],\n",
       "         [-0.8984375, -0.9375   , -0.953125 ],\n",
       "         ..., \n",
       "         [-0.5546875, -0.5390625, -0.6171875],\n",
       "         [-0.7109375, -0.703125 , -0.7578125],\n",
       "         [-0.9296875, -0.9296875, -0.9296875]],\n",
       "\n",
       "        [[-0.390625 , -0.3984375, -0.4453125],\n",
       "         [-0.515625 , -0.53125  , -0.5390625],\n",
       "         [-0.5625   , -0.59375  , -0.609375 ],\n",
       "         ..., \n",
       "         [-0.4765625, -0.453125 , -0.578125 ],\n",
       "         [-0.5703125, -0.5546875, -0.671875 ],\n",
       "         [-0.7734375, -0.765625 , -0.8046875]],\n",
       "\n",
       "        [[-0.4296875, -0.4375   , -0.46875  ],\n",
       "         [-0.46875  , -0.484375 , -0.4921875],\n",
       "         [-0.40625  , -0.4375   , -0.453125 ],\n",
       "         ..., \n",
       "         [-0.5625   , -0.5390625, -0.6484375],\n",
       "         [-0.5390625, -0.5078125, -0.5859375],\n",
       "         [-0.625    , -0.5859375, -0.609375 ]],\n",
       "\n",
       "        ..., \n",
       "        [[-0.2109375, -0.2890625, -0.359375 ],\n",
       "         [-0.09375  , -0.1796875, -0.2421875],\n",
       "         [-0.3046875, -0.3984375, -0.453125 ],\n",
       "         ..., \n",
       "         [-0.671875 , -0.7109375, -0.7421875],\n",
       "         [-0.7265625, -0.78125  , -0.8046875],\n",
       "         [-0.59375  , -0.6640625, -0.7109375]],\n",
       "\n",
       "        [[-0.25     , -0.328125 , -0.3828125],\n",
       "         [-0.25     , -0.34375  , -0.3828125],\n",
       "         [-0.453125 , -0.5625   , -0.5703125],\n",
       "         ..., \n",
       "         [-0.59375  , -0.6328125, -0.6875   ],\n",
       "         [-0.5625   , -0.6328125, -0.6796875],\n",
       "         [-0.484375 , -0.578125 , -0.6484375]],\n",
       "\n",
       "        [[-0.3046875, -0.390625 , -0.4375   ],\n",
       "         [-0.328125 , -0.4140625, -0.453125 ],\n",
       "         [-0.5390625, -0.6171875, -0.625    ],\n",
       "         ..., \n",
       "         [-0.578125 , -0.6171875, -0.671875 ],\n",
       "         [-0.4453125, -0.5234375, -0.5703125],\n",
       "         [-0.4453125, -0.5546875, -0.609375 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.796875 , -0.78125  , -0.8515625],\n",
       "         [-0.8125   , -0.796875 , -0.8828125],\n",
       "         [-0.7890625, -0.765625 , -0.8515625],\n",
       "         ..., \n",
       "         [-0.4765625, -0.40625  , -0.40625  ],\n",
       "         [-0.46875  , -0.421875 , -0.421875 ],\n",
       "         [-0.4765625, -0.4296875, -0.4296875]],\n",
       "\n",
       "        [[-0.6875   , -0.703125 , -0.8125   ],\n",
       "         [-0.640625 , -0.65625  , -0.78125  ],\n",
       "         [-0.6015625, -0.6171875, -0.75     ],\n",
       "         ..., \n",
       "         [-0.0546875, -0.0078125,  0.015625 ],\n",
       "         [ 0.0625   ,  0.109375 ,  0.109375 ],\n",
       "         [ 0.0078125,  0.0546875,  0.0546875]],\n",
       "\n",
       "        [[-0.6796875, -0.7109375, -0.84375  ],\n",
       "         [-0.609375 , -0.6328125, -0.78125  ],\n",
       "         [-0.578125 , -0.6015625, -0.765625 ],\n",
       "         ..., \n",
       "         [-0.3046875, -0.2734375, -0.25     ],\n",
       "         [-0.375    , -0.328125 , -0.328125 ],\n",
       "         [-0.3984375, -0.3515625, -0.34375  ]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.546875 ,  0.5078125,  0.4765625],\n",
       "         [ 0.59375  ,  0.5546875,  0.5234375],\n",
       "         [ 0.6484375,  0.609375 ,  0.578125 ],\n",
       "         ..., \n",
       "         [ 0.71875  ,  0.6796875,  0.640625 ],\n",
       "         [ 0.7109375,  0.6640625,  0.6328125],\n",
       "         [ 0.6640625,  0.6171875,  0.59375  ]],\n",
       "\n",
       "        [[ 0.5234375,  0.484375 ,  0.453125 ],\n",
       "         [ 0.546875 ,  0.5      ,  0.4765625],\n",
       "         [ 0.59375  ,  0.546875 ,  0.5234375],\n",
       "         ..., \n",
       "         [ 0.6640625,  0.6171875,  0.5859375],\n",
       "         [ 0.6640625,  0.609375 ,  0.578125 ],\n",
       "         [ 0.625    ,  0.5625   ,  0.53125  ]],\n",
       "\n",
       "        [[ 0.453125 ,  0.4140625,  0.3671875],\n",
       "         [ 0.53125  ,  0.46875  ,  0.4296875],\n",
       "         [ 0.578125 ,  0.515625 ,  0.4765625],\n",
       "         ..., \n",
       "         [ 0.6484375,  0.59375  ,  0.5390625],\n",
       "         [ 0.640625 ,  0.5859375,  0.5390625],\n",
       "         [ 0.609375 ,  0.5546875,  0.4921875]]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Perturb Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gradient, pred, logit, correct = sess.run(\n",
    "    [grad_loss_over_X,D,D_logits,correct_prediction], \n",
    "    feed_dict={X: X_batch, y: y_batch_real, keep_prob:1.0, is_train:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True False  True  True  True  True False\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True False False  True  True  True  True False  True  True  True  True\n",
      " False False  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "0.84375\n"
     ]
    }
   ],
   "source": [
    "accuracy_1 = sum(correct)*1.0/len(correct)\n",
    "print(correct)\n",
    "print(accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calculate the gradient based on the alternate labels\n",
    "gradient = sess.run(grad_loss_over_X, \n",
    "    feed_dict={X:X_batch, y: y_batch_alternate, keep_prob:1.0, is_train:False})\n",
    "\n",
    "gradient_image = (gradient - np.min(gradient))/(np.max(gradient)-np.min(gradient))\n",
    "fig = plot(gradient_image)\n",
    "plt.savefig('gradient.png', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# update the x \n",
    "gradient[gradient>0.0] = 1.0\n",
    "gradient[gradient<0.0] = -1.0\n",
    "\n",
    "X_batch_modified = X_batch - 10.0*0.007843137*gradient\n",
    "X_batch_modified[X_batch_modified>1.0] = 1.0\n",
    "X_batch_modified[X_batch_modified<-1.0] = -1.0\n",
    "\n",
    "pred_alternate, logit_alternate, correct_alternate = sess.run(\n",
    "    [D,D_logits,correct_prediction],\n",
    "    feed_dict={X:X_batch_modified, y: y_batch_real, keep_prob:1.0, is_train:False})\n",
    "  \n",
    "X_batch += 1.0\n",
    "X_batch /= 2.0\n",
    "X_batch[X_batch>1.0] = 1.0\n",
    "X_batch[X_batch<0.0] = 0.0\n",
    "fig = plot(X_batch)\n",
    "plt.savefig('X.png', bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "\n",
    "X_batch_modified += 1.0\n",
    "X_batch_modified /= 2.0\n",
    "X_batch_modified[X_batch_modified>1.0] = 1.0\n",
    "X_batch_modified[X_batch_modified<0.0] = 0.0\n",
    "fig = plot(X_batch_modified)\n",
    "plt.savefig('X_alternate.png', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False  True False\n",
      "  True False False False  True  True  True False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False  True False False  True  True False\n",
      " False False False  True]\n",
      "0.171875\n"
     ]
    }
   ],
   "source": [
    "print(correct_alternate)\n",
    "print(sum(correct_alternate)*1.0/len(correct_alternate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Perturb Image of Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch = np.load('X_batch_2.npy')\n",
    "labels_batch = np.load('labels_batch_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,32,32,3) (64,32,32,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b64466a026f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_batch_modified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.007843137\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX_batch_modified\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_batch_modified\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_batch_modified\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_batch_modified\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,32,32,3) (64,32,32,3) "
     ]
    }
   ],
   "source": [
    "#X_batch, labels_batch = sess.run([images_test, labels_test])\n",
    "real_labels = labels_batch\n",
    "y_batch_real = np.zeros((batch_size,10))\n",
    "y_batch_real[np.arange(batch_size),real_labels] = 1\n",
    "\n",
    "noise = np.random.normal(0.0,1.0, [64, 32, 32, 3])\n",
    "noise = ((noise - np.min(noise))/(np.max(noise)-np.min(noise))*2.0) - 1.0\n",
    "\n",
    "X_batch_modified = X_batch - 10.0*0.007843137*noise\n",
    "X_batch_modified[X_batch_modified>1.0] = 1.0\n",
    "X_batch_modified[X_batch_modified<-1.0] = -1.0\n",
    "\n",
    "pred1, logit_1, correct1 = sess.run(\n",
    "    [D,D_logits,correct_prediction],\n",
    "    feed_dict={X:X_batch, y: y_batch_real, keep_prob:1.0, is_train:False})\n",
    "\n",
    "pred_alternate1, logit_alternate1, correct_alternate1 = sess.run(\n",
    "    [D,D_logits,correct_prediction],\n",
    "    feed_dict={X:X_batch_modified, y: y_batch_real, keep_prob:1.0, is_train:False})\n",
    "\n",
    "\n",
    "\n",
    "X_batch += 1.0\n",
    "X_batch /= 2.0\n",
    "X_batch[X_batch>1.0] = 1.0\n",
    "X_batch[X_batch<0.0] = 0.0\n",
    "fig = plot(X_batch)\n",
    "plt.savefig('X_random.png', bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "\n",
    "noise += 1.0\n",
    "noise /= 2.0\n",
    "noise[noise>1.0] = 1.0\n",
    "noise[noise<0.0] = 0.0\n",
    "fig = plot(noise)\n",
    "plt.savefig('noise.png', bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "\n",
    "\n",
    "X_batch_modified += 1.0\n",
    "X_batch_modified /= 2.0\n",
    "X_batch_modified[X_batch_modified>1.0] = 1.0\n",
    "X_batch_modified[X_batch_modified<0.0] = 0.0\n",
    "fig = plot(X_batch_modified)\n",
    "plt.savefig('X_random_alternate.png', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('X_batch_2', X_batch)\n",
    "np.save('labels_batch_2',labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      " False  True  True  True False  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True False False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "0.859375\n",
      "[ True  True  True False  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True False\n",
      " False  True  True  True False  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True False  True  True  True  True\n",
      "  True  True False False  True  True  True  True  True  True  True False\n",
      "  True  True  True  True]\n",
      "0.828125\n"
     ]
    }
   ],
   "source": [
    "print(correct1)\n",
    "print(sum(correct1)*1.0/len(correct1))\n",
    "print(correct_alternate1)\n",
    "print(sum(correct_alternate1)*1.0/len(correct_alternate1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### High Activation Images for Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-3.63054276 -4.60294628 -5.40586519 -1.77940273 -2.53270292 -2.43257427\n",
      " -3.45420408 -6.25994778 -1.16589367 -4.82567406]\n",
      "50 [  4.4542551    8.05078125  11.15617657  11.17124081   6.32089281\n",
      "   9.12386894   7.90320587   8.79802608   9.22894764   7.72657442]\n",
      "100 [ 11.13281631  35.53216934  15.68049812  13.97629642   8.28242207\n",
      "  11.59186172  10.18539715  11.73096943  11.99155903  11.79137611]\n",
      "150 [ 11.62435436  81.28720093  18.8614521   15.74494457  10.43326378\n",
      "  12.95098019  11.80966949  13.29580021  13.47536087  14.0026083 ]\n",
      "200 [  15.56831264  118.57044983   21.52464485   18.08165932   11.13035011\n",
      "   13.95387936   12.98787689   14.79876614   14.37774181   16.47390747]\n",
      "250 [  18.72556686  144.58511353   23.6154213    19.47046471   11.90424156\n",
      "   14.66835403   14.1131506    15.86469841   15.5986414    18.01822472]\n",
      "300 [  21.56478119  161.02929688   25.47886086   20.81217194   11.91865826\n",
      "   15.5177021    13.69612694   16.39470291   16.01737595   19.34455299]\n",
      "350 [  20.75218773  172.23744202   27.02739334   21.79055977   12.78338242\n",
      "   15.83032131   15.39152336   17.04115868   16.79353905   20.63163948]\n",
      "400 [  25.90148163  180.21382141   28.32941246   23.06566238   11.02659416\n",
      "   17.10984421   15.85538578   17.76327515   17.42418098   21.69569588]\n",
      "450 [  26.57674599  185.69892883   29.2034111    24.04565239   13.37318134\n",
      "   18.24076843   16.22327423   18.41886139   17.91901016   23.00138474]\n",
      "500 [  28.39928246  189.7076416    29.8572731    24.95759392   13.87446785\n",
      "   18.78032303   16.73810768   18.80335617   18.91729736   23.45323563]\n",
      "550 [  27.7870388   192.98989868   30.47121048   25.75600815   12.79483414\n",
      "   19.2097187    16.99206543   19.08924866   19.73589897   25.12501526]\n",
      "600 [  29.83608437  195.7290802    31.0173893    26.38788223   13.35844517\n",
      "   19.79790878   17.21393585   19.12526321   20.37268066   25.55579567]\n",
      "650 [  30.66933632  197.98535156   31.42595291   26.96208763   14.4892807\n",
      "   20.16870499   16.80067253   19.43586159   21.2195282    26.27039909]\n",
      "700 [  31.78423309  199.75585938   31.63755226   27.54955292   14.6785078\n",
      "   20.54564285   17.88775826   19.8137989    21.69566727   26.59644508]\n",
      "750 [  32.74707413  201.14515686   32.06879044   28.02460098   14.30173492\n",
      "   19.385746     18.15872955   20.11104965   22.14698792   25.97058487]\n",
      "800 [  33.4331665   202.22866821   32.32413483   27.96695709   15.01039982\n",
      "   20.45686531   18.25590706   18.27572632   22.47468948   27.29750061]\n",
      "850 [  33.11672211  202.97566223   32.55208969   28.85530663   14.97718334\n",
      "   21.33839607   18.54135704   20.37457085   22.73060608   27.87278175]\n",
      "900 [  34.97444153  204.00695801   32.94052887   29.35528946   14.9344759\n",
      "   21.55682182   17.09162521   20.35101128   23.15351677   27.41729927]\n",
      "950 [  35.43283463  204.51831055   33.29525375   29.70983124   14.99977684\n",
      "   21.93369484   18.81121254   20.41177368   23.57610512   28.31611824]\n"
     ]
    }
   ],
   "source": [
    "X_batch,_ = sess.run([images_test, labels_test])\n",
    "X_batch = np.mean(X_batch,axis=0)[np.newaxis,:,:,:]\n",
    "X_batch = np.repeat(X_batch,10,axis=0)\n",
    "\n",
    "X_batch_modified = 1.0*X_batch\n",
    "\n",
    "t1 = time.time()\n",
    "for i in xrange(1000):\n",
    "    gradient, logits = sess.run([grad_logit_over_X, D_logits],\n",
    "        feed_dict={X:X_batch_modified, keep_prob:1.0, is_train:False})\n",
    "\n",
    "    X_batch_modified = X_batch_modified + 0.4*gradient - 0.005*X_batch_modified\n",
    "\n",
    "    X_batch_modified[X_batch_modified>1.0] = 1.0\n",
    "    X_batch_modified[X_batch_modified<-1.0] = -1.0\n",
    "    if i % 50 == 0:\n",
    "        print(i, logits[np.arange(10),np.arange(10)])\n",
    "\n",
    "X_batch_save = X_batch_modified*1.0\n",
    "X_batch_save += 1.0\n",
    "X_batch_save /= 2.0\n",
    "X_batch_save[X_batch_save>1.0] = 1.0\n",
    "X_batch_save[X_batch_save<0.0] = 0.0\n",
    "fig = plot_classes(X_batch_save)\n",
    "plt.savefig('classes2_GAN_1000.png', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### High Activation Image for Intermediate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n"
     ]
    }
   ],
   "source": [
    "X_batch,_ = sess.run([images_test, labels_test])\n",
    "X_batch = np.mean(X_batch,axis=0)[np.newaxis,:,:,:]\n",
    "X_batch = np.repeat(X_batch,64,axis=0)\n",
    "\n",
    "X_batch_modified = 1.0*X_batch\n",
    "\n",
    "t1 = time.time()\n",
    "for i in xrange(1000):\n",
    "    gradient, features = sess.run([grad_features_over_X, flat_features],\n",
    "        feed_dict={X:X_batch_modified, keep_prob:1.0, is_train:False})\n",
    "\n",
    "    X_batch_modified = X_batch_modified + 2.0*gradient - 0.001*X_batch_modified\n",
    "\n",
    "    X_batch_modified[X_batch_modified>1.0] = 1.0\n",
    "    X_batch_modified[X_batch_modified<-1.0] = -1.0\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "\n",
    "X_batch_save = X_batch_modified*1.0\n",
    "X_batch_save += 1.0\n",
    "X_batch_save /= 2.0\n",
    "X_batch_save[X_batch_save>1.0] = 1.0\n",
    "X_batch_save[X_batch_save<0.0] = 0.0\n",
    "fig = plot(X_batch_save)\n",
    "plt.savefig('features_cool_GAN.png', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3kernel",
   "language": "python",
   "name": "py3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
